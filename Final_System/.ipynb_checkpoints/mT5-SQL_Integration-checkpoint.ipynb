{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import _jsonnet\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2struct.commands.infer import Inferer\n",
    "from seq2struct.datasets.spider import SpiderItem\n",
    "from seq2struct.utils import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = json.loads(\n",
    "    _jsonnet.evaluate_file(\n",
    "        \"experiments/spider-configs/spider-mT5-large-en-pt-es-fr-train_en-pt-es-fr-eval.jsonnet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_path = exp_config[\"model_config\"]\n",
    "model_config_args = exp_config.get(\"model_config_args\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_config = json.loads(\n",
    "    _jsonnet.evaluate_file(\n",
    "        model_config_path, \n",
    "        tla_codes={'args': json.dumps(model_config_args)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_config[\"model\"][\"encoder_preproc\"][\"db_path\"] = \"data/sqlite_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING <class 'seq2struct.models.enc_dec.EncDecModel.Preproc'>: superfluous {'name': 'EncDec'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpiderEncoderT5Preproc Model: google/mt5-large\n",
      "No GAP - Generation-Augmented Pre-Training\n",
      "T5 load Model: google/mt5-large\n"
     ]
    }
   ],
   "source": [
    "inferer = Inferer(infer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = exp_config[\"logdir\"] + \"/bs=4,lr=1.0e-04,bert_lr=1.0e-05,end_lr=0e0,att=1\"\n",
    "#checkpoint_step = exp_config[\"eval_steps\"][0]\n",
    "checkpoint_step = 51100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/Databases/nl2sql/gap-text2sql/mrat-sql-gap/logdir/mT5-large-en-pt-es-fr-train/bs=4,lr=1.0e-04,bert_lr=1.0e-05,end_lr=0e0,att=1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING <class 'seq2struct.models.enc_dec.EncDecModel'>: superfluous {'decoder_preproc': {'grammar': {'clause_order': None, 'end_with_from': True, 'factorize_sketch': 2, 'include_literals': False, 'infer_from_conditions': True, 'name': 'spider', 'output_from': True, 'use_table_pointer': True}, 'save_path': 'data/spider-en-pt-es-fr/mT5-large-nl2code-1115,output_from=true,fs=2,emb=t5,cvlink', 'use_seq_elem_rules': True}, 'encoder_preproc': {'compute_cv_link': True, 'compute_sc_link': True, 'db_path': 'data/sqlite_files/', 'fix_issue_16_primary_keys': True, 'include_table_name_in_column': False, 'pretrained_checkpoint': 'models/mt5-large/pretrained_checkpoint/pytorch_model.bin', 'save_path': 'data/spider-en-pt-es-fr/mT5-large-nl2code-1115,output_from=true,fs=2,emb=t5,cvlink', 't5_version': 'google/mt5-large'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpiderEncoderT5 Model: google/mt5-large\n",
      "No GAP - Generation-Augmented Pre-Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/mt5-large were not used when initializing MT5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing MT5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MT5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.0312e+00, -4.2500e+00,  7.0000e+00,  ...,  6.0938e+00,\n",
      "         -8.0625e+00, -9.5000e+00],\n",
      "        [-7.7500e+00, -1.2125e+01, -2.3438e+00,  ..., -7.8438e+00,\n",
      "          9.1875e+00,  4.4375e+00],\n",
      "        [ 9.8047e-01,  1.0781e+00, -3.8672e-01,  ..., -1.0156e+00,\n",
      "         -4.7852e-01,  8.0078e-01],\n",
      "        ...,\n",
      "        [-1.4062e+00, -5.3516e-01,  1.7031e+00,  ..., -1.2891e+00,\n",
      "         -1.6504e-01, -1.0078e+00],\n",
      "        [-2.6953e-01,  6.2500e-01, -1.3828e+00,  ...,  1.8750e+00,\n",
      "          5.7373e-02,  1.4160e-01],\n",
      "        [-6.7188e-01,  5.8203e-01, -3.1250e-01,  ...,  5.3711e-03,\n",
      "         -2.1289e-01,  4.8828e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ -1.0312,  -4.2500,   7.0000,  ...,   6.0938,  -8.0625,  -9.5000],\n",
      "        [ -7.7500, -12.1250,  -2.3438,  ...,  -7.8438,   9.1875,   4.4375],\n",
      "        [  0.9805,   1.0781,  -0.3867,  ...,  -1.0156,  -0.4785,   0.8008],\n",
      "        ...,\n",
      "        [  0.8594,   0.1523,   0.1260,  ...,   1.2188,  -0.5195,  -0.9375],\n",
      "        [ -0.5430,   0.4277,  -0.5977,  ...,   1.5000,  -0.3730,  -0.5000],\n",
      "        [  1.3828,  -2.3906,  -1.0391,  ...,  -2.7344,   1.8672,   1.4688]],\n",
      "       requires_grad=True)\n",
      "Loading model from /mnt/Databases/nl2sql/gap-text2sql/mrat-sql-gap/logdir/mT5-large-en-pt-es-fr-train/bs=4,lr=1.0e-04,bert_lr=1.0e-05,end_lr=0e0,att=1/model_checkpoint-00051100\n"
     ]
    }
   ],
   "source": [
    "model = inferer.load_model(model_dir, checkpoint_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2struct.datasets.spider_lib.preprocess.get_tables import dump_db_json_schema\n",
    "from seq2struct.datasets.spider import load_tables_from_schema_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db_id = \"singer\"\n",
    "#db_id = \"concert_singer\"\n",
    "db_id =\"hospital_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_schema = dump_db_json_schema(\"data/sqlite_files/{db_id}/{db_id}.sqlite\".format(db_id=db_id), db_id)\n",
    "#my_schema = dump_db_json_schema(\"data/spider-en/database/{db_id}/{db_id}.sqlite\".format(db_id=db_id), db_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2struct.utils.api_utils import refine_schema_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db_id': 'hospital_1',\n",
       " 'table_names_original': ['Physician',\n",
       "  'Department',\n",
       "  'Affiliated_With',\n",
       "  'Procedures',\n",
       "  'Trained_In',\n",
       "  'Patient',\n",
       "  'Nurse',\n",
       "  'Appointment',\n",
       "  'Medication',\n",
       "  'Prescribes',\n",
       "  'Block',\n",
       "  'Room',\n",
       "  'On_Call',\n",
       "  'Stay',\n",
       "  'Undergoes'],\n",
       " 'table_names': ['physician',\n",
       "  'department',\n",
       "  'affiliated with',\n",
       "  'procedures',\n",
       "  'trained in',\n",
       "  'patient',\n",
       "  'nurse',\n",
       "  'appointment',\n",
       "  'medication',\n",
       "  'prescribes',\n",
       "  'block',\n",
       "  'room',\n",
       "  'on call',\n",
       "  'stay',\n",
       "  'undergoes'],\n",
       " 'column_names_original': [(-1, '*'),\n",
       "  (0, 'EmployeeID'),\n",
       "  (0, 'Name'),\n",
       "  (0, 'Position'),\n",
       "  (0, 'SSN'),\n",
       "  (1, 'DepartmentID'),\n",
       "  (1, 'Name'),\n",
       "  (1, 'Head'),\n",
       "  (2, 'Physician'),\n",
       "  (2, 'Department'),\n",
       "  (2, 'PrimaryAffiliation'),\n",
       "  (3, 'Code'),\n",
       "  (3, 'Name'),\n",
       "  (3, 'Cost'),\n",
       "  (4, 'Physician'),\n",
       "  (4, 'Treatment'),\n",
       "  (4, 'CertificationDate'),\n",
       "  (4, 'CertificationExpires'),\n",
       "  (5, 'SSN'),\n",
       "  (5, 'Name'),\n",
       "  (5, 'Address'),\n",
       "  (5, 'Phone'),\n",
       "  (5, 'InsuranceID'),\n",
       "  (5, 'PCP'),\n",
       "  (6, 'EmployeeID'),\n",
       "  (6, 'Name'),\n",
       "  (6, 'Position'),\n",
       "  (6, 'Registered'),\n",
       "  (6, 'SSN'),\n",
       "  (7, 'AppointmentID'),\n",
       "  (7, 'Patient'),\n",
       "  (7, 'PrepNurse'),\n",
       "  (7, 'Physician'),\n",
       "  (7, 'Start'),\n",
       "  (7, 'End'),\n",
       "  (7, 'ExaminationRoom'),\n",
       "  (8, 'Code'),\n",
       "  (8, 'Name'),\n",
       "  (8, 'Brand'),\n",
       "  (8, 'Description'),\n",
       "  (9, 'Physician'),\n",
       "  (9, 'Patient'),\n",
       "  (9, 'Medication'),\n",
       "  (9, 'Date'),\n",
       "  (9, 'Appointment'),\n",
       "  (9, 'Dose'),\n",
       "  (10, 'BlockFloor'),\n",
       "  (10, 'BlockCode'),\n",
       "  (11, 'RoomNumber'),\n",
       "  (11, 'RoomType'),\n",
       "  (11, 'BlockFloor'),\n",
       "  (11, 'BlockCode'),\n",
       "  (11, 'Unavailable'),\n",
       "  (12, 'Nurse'),\n",
       "  (12, 'BlockFloor'),\n",
       "  (12, 'BlockCode'),\n",
       "  (12, 'OnCallStart'),\n",
       "  (12, 'OnCallEnd'),\n",
       "  (13, 'StayID'),\n",
       "  (13, 'Patient'),\n",
       "  (13, 'Room'),\n",
       "  (13, 'StayStart'),\n",
       "  (13, 'StayEnd'),\n",
       "  (14, 'Patient'),\n",
       "  (14, 'Procedures'),\n",
       "  (14, 'Stay'),\n",
       "  (14, 'DateUndergoes'),\n",
       "  (14, 'Physician'),\n",
       "  (14, 'AssistingNurse')],\n",
       " 'column_names': [(-1, '*'),\n",
       "  (0, 'employeeid'),\n",
       "  (0, 'name'),\n",
       "  (0, 'position'),\n",
       "  (0, 'ssn'),\n",
       "  (1, 'departmentid'),\n",
       "  (1, 'name'),\n",
       "  (1, 'head'),\n",
       "  (2, 'physician'),\n",
       "  (2, 'department'),\n",
       "  (2, 'primaryaffiliation'),\n",
       "  (3, 'code'),\n",
       "  (3, 'name'),\n",
       "  (3, 'cost'),\n",
       "  (4, 'physician'),\n",
       "  (4, 'treatment'),\n",
       "  (4, 'certificationdate'),\n",
       "  (4, 'certificationexpires'),\n",
       "  (5, 'ssn'),\n",
       "  (5, 'name'),\n",
       "  (5, 'address'),\n",
       "  (5, 'phone'),\n",
       "  (5, 'insuranceid'),\n",
       "  (5, 'pcp'),\n",
       "  (6, 'employeeid'),\n",
       "  (6, 'name'),\n",
       "  (6, 'position'),\n",
       "  (6, 'registered'),\n",
       "  (6, 'ssn'),\n",
       "  (7, 'appointmentid'),\n",
       "  (7, 'patient'),\n",
       "  (7, 'prepnurse'),\n",
       "  (7, 'physician'),\n",
       "  (7, 'start'),\n",
       "  (7, 'end'),\n",
       "  (7, 'examinationroom'),\n",
       "  (8, 'code'),\n",
       "  (8, 'name'),\n",
       "  (8, 'brand'),\n",
       "  (8, 'description'),\n",
       "  (9, 'physician'),\n",
       "  (9, 'patient'),\n",
       "  (9, 'medication'),\n",
       "  (9, 'date'),\n",
       "  (9, 'appointment'),\n",
       "  (9, 'dose'),\n",
       "  (10, 'blockfloor'),\n",
       "  (10, 'blockcode'),\n",
       "  (11, 'roomnumber'),\n",
       "  (11, 'roomtype'),\n",
       "  (11, 'blockfloor'),\n",
       "  (11, 'blockcode'),\n",
       "  (11, 'unavailable'),\n",
       "  (12, 'nurse'),\n",
       "  (12, 'blockfloor'),\n",
       "  (12, 'blockcode'),\n",
       "  (12, 'oncallstart'),\n",
       "  (12, 'oncallend'),\n",
       "  (13, 'stayid'),\n",
       "  (13, 'patient'),\n",
       "  (13, 'room'),\n",
       "  (13, 'staystart'),\n",
       "  (13, 'stayend'),\n",
       "  (14, 'patient'),\n",
       "  (14, 'procedures'),\n",
       "  (14, 'stay'),\n",
       "  (14, 'dateundergoes'),\n",
       "  (14, 'physician'),\n",
       "  (14, 'assistingnurse')],\n",
       " 'column_types': ['text',\n",
       "  'number',\n",
       "  'text',\n",
       "  'text',\n",
       "  'number',\n",
       "  'number',\n",
       "  'text',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'boolean',\n",
       "  'number',\n",
       "  'text',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'time',\n",
       "  'time',\n",
       "  'number',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'text',\n",
       "  'text',\n",
       "  'boolean',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'time',\n",
       "  'time',\n",
       "  'text',\n",
       "  'number',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'time',\n",
       "  'number',\n",
       "  'text',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'text',\n",
       "  'number',\n",
       "  'number',\n",
       "  'boolean',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'time',\n",
       "  'time',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'time',\n",
       "  'time',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'time',\n",
       "  'number',\n",
       "  'number'],\n",
       " 'primary_keys': [1, 5, 8, 11, 14, 18, 24, 29, 36, 40, 46, 48, 53, 58, 63],\n",
       " 'foreign_keys': [[7, 1],\n",
       "  [9, 5],\n",
       "  [8, 1],\n",
       "  [15, 11],\n",
       "  [14, 1],\n",
       "  [23, 1],\n",
       "  [32, 1],\n",
       "  [31, 24],\n",
       "  [30, 18],\n",
       "  [44, 29],\n",
       "  [42, 36],\n",
       "  [41, 18],\n",
       "  [40, 1],\n",
       "  [50, 46],\n",
       "  [51, 47],\n",
       "  [54, 46],\n",
       "  [55, 47],\n",
       "  [53, 24],\n",
       "  [60, 48],\n",
       "  [59, 18],\n",
       "  [68, 24],\n",
       "  [67, 1],\n",
       "  [65, 58],\n",
       "  [64, 11],\n",
       "  [63, 18]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to change your schema name, then run this; Otherwise you can skip this.\n",
    "#refine_schema_names(my_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema, eval_foreign_key_maps = load_tables_from_schema_dict(my_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hospital_1'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = registry.construct('dataset_infer', {\n",
    "   \"name\": \"spider\", \"schemas\": schema, \"eval_foreign_key_maps\": eval_foreign_key_maps, \n",
    "    \"db_path\": \"data/sqlite_files/\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, schema in dataset.schemas.items():\n",
    "    model.preproc.enc_preproc._preprocess_schema(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_schema = dataset.schemas[db_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(question):\n",
    "    data_item = SpiderItem(\n",
    "            text=None,  # intentionally None -- should be ignored when the tokenizer is set correctly\n",
    "            code=None,\n",
    "            schema=spider_schema,\n",
    "            orig_schema=spider_schema.orig,\n",
    "            orig={\"question\": question}\n",
    "        )\n",
    "    model.preproc.clear_items()\n",
    "    enc_input = model.preproc.enc_preproc.preprocess_item(data_item, None)\n",
    "    preproc_data = enc_input, None\n",
    "    with torch.no_grad():\n",
    "        output = inferer._infer_one(model, data_item, preproc_data, beam_size=1, use_heuristic=True)\n",
    "    #print(f\"orig_question: {output[0]['orig_question']}\")\n",
    "    #print(f\"model_output: {output[0]['model_output']}\")\n",
    "    #print(f\"score: {output[0]['score']}\") \n",
    "    return output[0][\"inferred_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening path: /mnt/Files/integration/nl2sql/\n",
      "\n",
      "New request arrive:\n",
      "Encontre os nomes das enfermeiras que estão de plantão.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marchanjo/miniconda3/envs/gap-text2sql/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT DISTINCT Nurse.Name FROM Nurse JOIN On_Call\n",
      "\n",
      "New request arrive:\n",
      "Encontre os nomes das enfermeiras que estão de plantão.\n",
      "SELECT DISTINCT Nurse.Name FROM Nurse JOIN On_Call\n",
      "\n",
      "New request arrive:\n",
      "Qual departamento possui o maior número de funcionários?\n",
      "SELECT Department.Name FROM Department GROUP BY Department.DepartmentID ORDER BY Count(Department.DepartmentID) Desc LIMIT 1\n",
      "\n",
      "New request arrive:\n",
      "Qual departamento possui o maior número de funcionários?\n",
      "SELECT Department.Name FROM Department GROUP BY Department.DepartmentID ORDER BY Count(Department.DepartmentID) Desc LIMIT 1\n",
      "\n",
      "New request arrive:\n",
      "Encontre os três procedimentos mais caros\n",
      "SELECT Procedures.Name FROM Procedures ORDER BY Procedures.Cost Asc LIMIT 1\n",
      "\n",
      "New request arrive:\n",
      "Encontre os 3 procedimentos mais caros\n",
      "SELECT Procedures.Name FROM Procedures ORDER BY Procedures.Cost Asc LIMIT 1\n"
     ]
    }
   ],
   "source": [
    "#aguarda pergunta e responde a resposta (inferência)\n",
    "\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "path = \"/mnt/Files/integration/nl2sql/\"\n",
    "print(f\"Listening path: {path}\")\n",
    "\n",
    "while 1:#loop infinito tem que parar manualmente\n",
    "    time.sleep(0.5)#em segundos, delay para não consumir todo o processador da máquina.\n",
    "    \n",
    "    ready = os.path.exists(path + \"in/ready.txt\")\n",
    "    question = os.path.exists(path + \"in/question.csv\")\n",
    "    #print(f\"Ready = {ready}\\nQuestion = {question}\")\n",
    "        \n",
    "    if ready == True and question == True:\n",
    "        print(\"\\nNew request arrive:\")\n",
    "                \n",
    "        csv_out = open(path + \"out/queries.csv\", \"w\", encoding='utf8')\n",
    "        ready_out = open(path + \"out/ready.txt\", \"w\", encoding='utf8')\n",
    "        ready_out.write(\"Done\")#qualquer conteúdo       \n",
    "       \n",
    "        \n",
    "        with open(path + \"in/question.csv\", newline = '', encoding='utf8') as csv_in:\n",
    "            csv_in_reader = csv.reader(csv_in, delimiter=';')\n",
    "            for csv_i in csv_in_reader:\n",
    "                print(csv_i[0])\n",
    "                code = infer(csv_i[0])               \n",
    "                print(code)\n",
    "                csv_out.write(f\"{csv_i[0]};{code}\\n\")\n",
    "                break #só o primeiro               \n",
    "        csv_out.close()   \n",
    "        ready_out.close()\n",
    "        os.remove(path + \"in/ready.txt\") #Deletado indica que terminou o processamento\n",
    "        os.remove(path + \"in/question.csv\")#Deletado indica que terminou o processamento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
