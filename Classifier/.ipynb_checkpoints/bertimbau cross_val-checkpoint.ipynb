{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "442a6b47",
   "metadata": {},
   "source": [
    "# BERTimbau Classifier - Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c10a36",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ec61af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 19:05:42.625646: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, matthews_corrcoef\n",
    "import pandas as pd\n",
    "import time as t\n",
    "import statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae4ba6",
   "metadata": {},
   "source": [
    "## Reading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba7ae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Loading the MSMARCO Dataset\n",
    "MSMARCO = pd.read_csv(\"MSMARCO_biomedical_PT/train.csv\")[[\"question_pt\"]]\n",
    "\n",
    "# Cleaning MSMARCO Dataset\n",
    "MSMARCO['question_pt'] = MSMARCO['question_pt'].apply(lambda x: x.rstrip('\\n'))\n",
    "MSMARCO['question_pt'] = MSMARCO['question_pt'].apply(lambda x: x.rstrip('\\t'))\n",
    "MSMARCO['question_pt'] = MSMARCO['question_pt'].apply(lambda x: x.rstrip('?'))\n",
    "MSMARCO['question_pt'] = MSMARCO['question_pt'].apply(lambda x: x.rstrip('.'))\n",
    "\n",
    "#MSMARCO.tail(20)\n",
    "\n",
    "\n",
    "\n",
    "# Loading the MIMIC Dataset\n",
    "MIMIC_dev = pd.read_csv(\"MIMICSQL_PT/dev.csv\")[[\"question_pt\"]]\n",
    "MIMIC_train = pd.read_csv(\"MIMICSQL_PT/train.csv\")[[\"question_pt\"]]\n",
    "\n",
    "MIMIC = pd.concat([MIMIC_dev, MIMIC_train], ignore_index=True)\n",
    "\n",
    "# Cleaning MIMIC Dataset\n",
    "MIMIC['question_pt'] = MIMIC['question_pt'].apply(lambda x: x.rstrip('\\n'))\n",
    "MIMIC['question_pt'] = MIMIC['question_pt'].apply(lambda x: x.rstrip('\\t'))\n",
    "MIMIC['question_pt'] = MIMIC['question_pt'].apply(lambda x: x.rstrip('?'))\n",
    "MIMIC['question_pt'] = MIMIC['question_pt'].apply(lambda x: x.rstrip('.'))\n",
    "\n",
    "\n",
    "\n",
    "# Loading the SPIDER Dataset\n",
    "SPIDER_med = pd.read_csv(\"SPIDER/medicine_enzyme_interaction.txt\", sep=\";;\", header=None)\n",
    "SPIDER_protein = pd.read_csv(\"SPIDER/protein_institute.txt\", sep=\";;\", header=None)\n",
    "SPIDER_scientist = pd.read_csv(\"SPIDER/scientist_1.txt\", sep=\";;\", header=None)\n",
    "\n",
    "SPIDER = pd.concat([SPIDER_med, SPIDER_protein, SPIDER_scientist], ignore_index=True)\n",
    "SPIDER.columns = [\"question_pt\"]\n",
    "\n",
    "# Cleaning SPIDER Dataset\n",
    "SPIDER['question_pt'] = SPIDER['question_pt'].apply(lambda x: x.rstrip('\\n'))\n",
    "SPIDER['question_pt'] = SPIDER['question_pt'].apply(lambda x: x.rstrip('\\t'))\n",
    "SPIDER['question_pt'] = SPIDER['question_pt'].apply(lambda x: x.rstrip('?'))\n",
    "SPIDER['question_pt'] = SPIDER['question_pt'].apply(lambda x: x.rstrip('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f3024",
   "metadata": {},
   "source": [
    "## Joining Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f1e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join datasets\n",
    "\n",
    "\n",
    "MSMARCO[\"type\"] = 1\n",
    "MIMIC[\"type\"] = 0\n",
    "SPIDER[\"type\"] = 0\n",
    "\n",
    "\n",
    "tp0 = pd.concat([MIMIC, SPIDER], ignore_index=True)\n",
    "\n",
    "df = pd.concat([MSMARCO.head(tp0.count()[0]), tp0], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb50a712",
   "metadata": {},
   "source": [
    "## Cross Validation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac706b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:615: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e63d431c844b7baf102b1cec908ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db21c495b5e64a48be842552b8c1e25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf019007a5e47f69bc07a2dd7c3094e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d508a24d09294217a002e2e6de2249c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ac4bd86de040388458eaa1abbde175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ae2dec5f26413d97eea5bca72f7018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0161247bb9cc48bd90e116452e44d8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:1401: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed10b6447844478898e3e4a5138ff82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bbb09bb92d41c9bcd260f1078f8f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff928596d174ef29f61db9608a6bbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fff2d2b5284c9ab77eab5cb770e6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# RESULTS #################\n",
      "\n",
      "Accumulated data:\n",
      ">> results_acc [0.9994514536478333]\n",
      ">> results_mcc [0.9989035074529009]\n",
      ">> results_f1_weighted [0.9994514533177142]\n",
      ">> results_f1_micro [0.9994514536478333]\n",
      ">> results_f1_macro [0.9994514529875953]\n",
      ">> results_eval_loss [0.0019295816069771128]\n",
      "\n",
      "AVGs:\n",
      ">> avg_acc: 0.999\n",
      ">> avg_mcc: 0.999\n",
      ">> avg_f1_weighted: 0.999\n",
      ">> avg_f1_micro: 0.999\n",
      ">> avg_f1_macro: 0.999\n",
      ">> avg_results_eval_loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:615: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2ea922e0dd4b3e9f44ad95253f38b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2976de6371543ee84df73b65067861c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0b5a0d6f0f4b0d97a2dbf9e142b3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca9d4fa03bd4e159672a635c2e73684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d857fa6e81f14e8f86c3ced96a0c29d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f30bbffacf49459184e3e174d400fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f336296380ff418db290672ed02f4ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:1401: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851bdead0822431da5f3cc9a2adc4ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80b5aa8e2dc496d855d46fcd947f955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cf9a1359cd4505a0765b48faeefed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb82f20c376647a6acad6c5207138fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# RESULTS #################\n",
      "\n",
      "Accumulated data:\n",
      ">> results_acc [0.9994514536478333, 1.0]\n",
      ">> results_mcc [0.9989035074529009, 1.0]\n",
      ">> results_f1_weighted [0.9994514533177142, 1.0]\n",
      ">> results_f1_micro [0.9994514536478333, 1.0]\n",
      ">> results_f1_macro [0.9994514529875953, 1.0]\n",
      ">> results_eval_loss [0.0019295816069771128, 0.00014591706853376278]\n",
      "\n",
      "AVGs:\n",
      ">> avg_acc: 1.0\n",
      ">> avg_mcc: 0.999\n",
      ">> avg_f1_weighted: 1.0\n",
      ">> avg_f1_micro: 1.0\n",
      ">> avg_f1_macro: 1.0\n",
      ">> avg_results_eval_loss: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:615: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba4024ae47a42eba9032b116beeddc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233415d298f24b73b7b8edcc7dd16416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ffbda9a44b4622a932fba66ec690bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5c20e01e7949fd9a0fc5efb61d6539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49cb70205b2d415d9d5a57d690ebee3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc15cef74b494ad8b8a910819f4e38b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f08ee1560f483291559a7fa915d7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:1401: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b630bc70f9498285b9201ec185b29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3426d0320faf4b66834b586315623fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc5297784904e8ea0b2cb1796656978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb788f9763c43d08ae5ffa521c20829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# RESULTS #################\n",
      "\n",
      "Accumulated data:\n",
      ">> results_acc [0.9994514536478333, 1.0, 0.9989029072956664]\n",
      ">> results_mcc [0.9989035074529009, 1.0, 0.997808213248941]\n",
      ">> results_f1_weighted [0.9994514533177142, 1.0, 0.9989029053149495]\n",
      ">> results_f1_micro [0.9994514536478333, 1.0, 0.9989029072956664]\n",
      ">> results_f1_macro [0.9994514529875953, 1.0, 0.9989029043245911]\n",
      ">> results_eval_loss [0.0019295816069771128, 0.00014591706853376278, 0.007889651173850883]\n",
      "\n",
      "AVGs:\n",
      ">> avg_acc: 0.999\n",
      ">> avg_mcc: 0.999\n",
      ">> avg_f1_weighted: 0.999\n",
      ">> avg_f1_micro: 0.999\n",
      ">> avg_f1_macro: 0.999\n",
      ">> avg_results_eval_loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:615: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f513767a4ddc4ae3a0e89ace87075260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b447ceb07f0477f89fa24e40699b664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9568f45ec646fc88c45af92c9d4973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d171825703f94d1eb5f72b3dc23bef08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3a6677ee2e474187a428f6f9d64bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e6a36cdfcf4d37b6a0ad10feb573ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54c5d55e3e94b349a2f79ac639c5372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:1401: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7124b7bf70564dffad3308f36c85e7de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cbf0ee34d640a1bc2814c55f1d4425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef8652663a14e7c87b7822ae376f3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4125ccbeed9a46fc8d3d516d627e74d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# RESULTS #################\n",
      "\n",
      "Accumulated data:\n",
      ">> results_acc [0.9994514536478333, 1.0, 0.9989029072956664, 1.0]\n",
      ">> results_mcc [0.9989035074529009, 1.0, 0.997808213248941, 1.0]\n",
      ">> results_f1_weighted [0.9994514533177142, 1.0, 0.9989029053149495, 1.0]\n",
      ">> results_f1_micro [0.9994514536478333, 1.0, 0.9989029072956664, 1.0]\n",
      ">> results_f1_macro [0.9994514529875953, 1.0, 0.9989029043245911, 1.0]\n",
      ">> results_eval_loss [0.0019295816069771128, 0.00014591706853376278, 0.007889651173850883, 3.061985977949103e-05]\n",
      "\n",
      "AVGs:\n",
      ">> avg_acc: 1.0\n",
      ">> avg_mcc: 0.999\n",
      ">> avg_f1_weighted: 1.0\n",
      ">> avg_f1_micro: 1.0\n",
      ">> avg_f1_macro: 1.0\n",
      ">> avg_results_eval_loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:615: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f562bd03346a42a8a31daf8bd147b462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667af7e329d6421abb36c6c71f0c631f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d4aeb2e0ec45fc83e5b07fea134945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7588932153e41369e710f3b06fdec8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b680daae5ce14cfc943279a2b0d31b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae79b325dcf84ec3bbd3d512a46216d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac6b36ef39f4d01971c5d7791c56ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:1401: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0146dd7717f4a86ab23efc42be04ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb720e58952412984999e35fc3302bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50dfa029bfb411b856701a1b7d135b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696a775a969a4bc6b1b1f00272bea7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# RESULTS #################\n",
      "\n",
      "Accumulated data:\n",
      ">> results_acc [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828]\n",
      ">> results_mcc [0.9989035074529009, 1.0, 0.997808213248941, 1.0, 0.9989029069653665]\n",
      ">> results_f1_weighted [0.9994514533177142, 1.0, 0.9989029053149495, 1.0, 0.9994511524142516]\n",
      ">> results_f1_micro [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828]\n",
      ">> results_f1_macro [0.9994514529875953, 1.0, 0.9989029043245911, 1.0, 0.9994511524142516]\n",
      ">> results_eval_loss [0.0019295816069771128, 0.00014591706853376278, 0.007889651173850883, 3.061985977949103e-05, 0.005370998285893859]\n",
      "\n",
      "AVGs:\n",
      ">> avg_acc: 1.0\n",
      ">> avg_mcc: 0.999\n",
      ">> avg_f1_weighted: 1.0\n",
      ">> avg_f1_micro: 1.0\n",
      ">> avg_f1_macro: 1.0\n",
      ">> avg_results_eval_loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:615: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bd81a90353407db9648a4a096b9a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906b195bc8d94d69b56337a15a4d87dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83561b10baaf4b69b7e6fdaeeab6dcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25668672e6bd404e8258876bdd1386ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d90bf4aba14537a6b2abfb5d5b4f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333fbae04e274bcab15e9d449abee100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17406e3d66a84204bc7c540c6f2a0d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:1401: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ed3a55871d40eaaa3c57a6d1315252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01471510ae824e3387a992f422b75abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfaa1551383b40159690190d4fc959a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab439cde2e0b439ea81f32c8a6c544e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# RESULTS #################\n",
      "\n",
      "Accumulated data:\n",
      ">> results_acc [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828, 0.9994511525795828]\n",
      ">> results_mcc [0.9989035074529009, 1.0, 0.997808213248941, 1.0, 0.9989029069653665, 0.9989029069653665]\n",
      ">> results_f1_weighted [0.9994514533177142, 1.0, 0.9989029053149495, 1.0, 0.9994511524142516, 0.9994511524142516]\n",
      ">> results_f1_micro [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828, 0.9994511525795828]\n",
      ">> results_f1_macro [0.9994514529875953, 1.0, 0.9989029043245911, 1.0, 0.9994511524142516, 0.9994511524142516]\n",
      ">> results_eval_loss [0.0019295816069771128, 0.00014591706853376278, 0.007889651173850883, 3.061985977949103e-05, 0.005370998285893859, 0.00641160039910111]\n",
      "\n",
      "AVGs:\n",
      ">> avg_acc: 1.0\n",
      ">> avg_mcc: 0.999\n",
      ">> avg_f1_weighted: 1.0\n",
      ">> avg_f1_micro: 1.0\n",
      ">> avg_f1_macro: 1.0\n",
      ">> avg_results_eval_loss: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:615: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff2636831114e088772b5ae198ac134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59072951caf843819ddf3ac9f4858055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eed80d1c15146afa6194c2a735d57a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348e7530b3f5427d863a03c8b70f975d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b2d2dcf3e049e5b490d33c968a11e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8cdf546528c4020a87b6f96d1a49b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff9fb03767d4fd6b10ed1a200ead955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:1401: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3de7e30d95440e9ab9f20d0b207394a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48811073ed65448d9e77717d5c9f704d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61f2d80d84146b8ac1eb3729492d8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f792f1608a524aa0ba956d7daad7fe45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# RESULTS #################\n",
      "\n",
      "Accumulated data:\n",
      ">> results_acc [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828, 0.9994511525795828, 0.9983534577387486]\n",
      ">> results_mcc [0.9989035074529009, 1.0, 0.997808213248941, 1.0, 0.9989029069653665, 0.9989029069653665, 0.996707515961047]\n",
      ">> results_f1_weighted [0.9994514533177142, 1.0, 0.9989029053149495, 1.0, 0.9994511524142516, 0.9994511524142516, 0.9983534572427548]\n",
      ">> results_f1_micro [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828, 0.9994511525795828, 0.9983534577387486]\n",
      ">> results_f1_macro [0.9994514529875953, 1.0, 0.9989029043245911, 1.0, 0.9994511524142516, 0.9994511524142516, 0.9983534572427548]\n",
      ">> results_eval_loss [0.0019295816069771128, 0.00014591706853376278, 0.007889651173850883, 3.061985977949103e-05, 0.005370998285893859, 0.00641160039910111, 0.010651623390322927]\n",
      "\n",
      "AVGs:\n",
      ">> avg_acc: 0.999\n",
      ">> avg_mcc: 0.999\n",
      ">> avg_f1_weighted: 0.999\n",
      ">> avg_f1_micro: 0.999\n",
      ">> avg_f1_macro: 0.999\n",
      ">> avg_results_eval_loss: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:615: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaae11903d1b4db48538d8200f706497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6324462a38a441c4b1aee5ef81fc957b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa1f02d020e4c7da635f13cdb7f06ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45aab46e34974debbbd184655070521b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9456617a4754170afe2874dc6b731b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffedba21a2014c1793a57ab3f0496e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbd89600a5d4fe5aa97eae6f712d6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:1401: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8610091b994357ad0e23f18828c72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e71ee1dc16e42ddaa10948ded9a7d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48539ee15334f40b4ba523222d67189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb204d8988f42c8a2693549ebb1b788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# RESULTS #################\n",
      "\n",
      "Accumulated data:\n",
      ">> results_acc [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828, 0.9994511525795828, 0.9983534577387486, 1.0]\n",
      ">> results_mcc [0.9989035074529009, 1.0, 0.997808213248941, 1.0, 0.9989029069653665, 0.9989029069653665, 0.996707515961047, 1.0]\n",
      ">> results_f1_weighted [0.9994514533177142, 1.0, 0.9989029053149495, 1.0, 0.9994511524142516, 0.9994511524142516, 0.9983534572427548, 1.0]\n",
      ">> results_f1_micro [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828, 0.9994511525795828, 0.9983534577387486, 1.0]\n",
      ">> results_f1_macro [0.9994514529875953, 1.0, 0.9989029043245911, 1.0, 0.9994511524142516, 0.9994511524142516, 0.9983534572427548, 1.0]\n",
      ">> results_eval_loss [0.0019295816069771128, 0.00014591706853376278, 0.007889651173850883, 3.061985977949103e-05, 0.005370998285893859, 0.00641160039910111, 0.010651623390322927, 0.00022643909352681427]\n",
      "\n",
      "AVGs:\n",
      ">> avg_acc: 0.999\n",
      ">> avg_mcc: 0.999\n",
      ">> avg_f1_weighted: 0.999\n",
      ">> avg_f1_micro: 0.999\n",
      ">> avg_f1_macro: 0.999\n",
      ">> avg_results_eval_loss: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:615: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a043bfc3c054d5da7947ebeafaa31da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48d081a181f495082d2087893ff57fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b35d08409ca4bf68c2eee0feb90b48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc1651c64424416a9bdfefd33aab68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11d4707d0a543abbd1bf6b7cbd202a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384ff02c892d40a19fad6af18fd6d988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23df02a89db8465abb3add056a2f1d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:1401: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7efcf9503674468ad6c2823c6da7f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b0fafe2c5c4d7ab54e8f0c36c12d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0847e7f52b644b5b6d6c7f28474ea8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc589183a0f54e818da86c32a4af4366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# RESULTS #################\n",
      "\n",
      "Accumulated data:\n",
      ">> results_acc [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828, 0.9994511525795828, 0.9983534577387486, 1.0, 0.9989023051591658]\n",
      ">> results_mcc [0.9989035074529009, 1.0, 0.997808213248941, 1.0, 0.9989029069653665, 0.9989029069653665, 0.996707515961047, 1.0, 0.9978070149043516]\n",
      ">> results_f1_weighted [0.9994514533177142, 1.0, 0.9989029053149495, 1.0, 0.9994511524142516, 0.9994511524142516, 0.9983534572427548, 1.0, 0.9989023038365143]\n",
      ">> results_f1_micro [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828, 0.9994511525795828, 0.9983534577387486, 1.0, 0.9989023051591658]\n",
      ">> results_f1_macro [0.9994514529875953, 1.0, 0.9989029043245911, 1.0, 0.9994511524142516, 0.9994511524142516, 0.9983534572427548, 1.0, 0.9989023038365143]\n",
      ">> results_eval_loss [0.0019295816069771128, 0.00014591706853376278, 0.007889651173850883, 3.061985977949103e-05, 0.005370998285893859, 0.00641160039910111, 0.010651623390322927, 0.00022643909352681427, 0.00681278284370516]\n",
      "\n",
      "AVGs:\n",
      ">> avg_acc: 0.999\n",
      ">> avg_mcc: 0.999\n",
      ">> avg_f1_weighted: 0.999\n",
      ">> avg_f1_micro: 0.999\n",
      ">> avg_f1_macro: 0.999\n",
      ">> avg_results_eval_loss: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:615: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc900306bb2b4cac9c07f57c440f7814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33d5cd983f54c4aac5a17226a8ed810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cccf70ca4e64406a3c4f842b67fb20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10d513edae54b6091479cd70b200b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee9a7ae0cc843d59082d7e77a4e8918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f6e7805cbc46ff83c6b2fe6d183b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9d9bb3078246eeb77734da86939c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/4101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:1401: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655100f8a1e24ad7837755549aa658f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb2295c1ae646eba721e058df4342b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc4372481e541609634b218cf34eebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99115ce9e4cb45d489fb0576366870e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# RESULTS #################\n",
      "\n",
      "Accumulated data:\n",
      ">> results_acc [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828, 0.9994511525795828, 0.9983534577387486, 1.0, 0.9989023051591658, 0.9989023051591658]\n",
      ">> results_mcc [0.9989035074529009, 1.0, 0.997808213248941, 1.0, 0.9989029069653665, 0.9989029069653665, 0.996707515961047, 1.0, 0.9978070149043516, 0.9978070149043516]\n",
      ">> results_f1_weighted [0.9994514533177142, 1.0, 0.9989029053149495, 1.0, 0.9994511524142516, 0.9994511524142516, 0.9983534572427548, 1.0, 0.9989023038365143, 0.9989023038365143]\n",
      ">> results_f1_micro [0.9994514536478333, 1.0, 0.9989029072956664, 1.0, 0.9994511525795828, 0.9994511525795828, 0.9983534577387486, 1.0, 0.9989023051591658, 0.9989023051591658]\n",
      ">> results_f1_macro [0.9994514529875953, 1.0, 0.9989029043245911, 1.0, 0.9994511524142516, 0.9994511524142516, 0.9983534572427548, 1.0, 0.9989023038365143, 0.9989023038365143]\n",
      ">> results_eval_loss [0.0019295816069771128, 0.00014591706853376278, 0.007889651173850883, 3.061985977949103e-05, 0.005370998285893859, 0.00641160039910111, 0.010651623390322927, 0.00022643909352681427, 0.00681278284370516, 0.010110419022694578]\n",
      "\n",
      "AVGs:\n",
      ">> avg_acc: 0.999\n",
      ">> avg_mcc: 0.999\n",
      ">> avg_f1_weighted: 0.999\n",
      ">> avg_f1_micro: 0.999\n",
      ">> avg_f1_macro: 0.999\n",
      ">> avg_results_eval_loss: 0.005\n",
      "\n",
      ">> Elapsed time: 754.56min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = t.time()\n",
    "\n",
    "model_args = {\n",
    "    'num_train_epochs': 5,\n",
    "    'learning_rate': 5e-5,\n",
    "    'max_seq_length': 512,\n",
    "    'n_gpu': 2,\n",
    "    'optimizer': 'AdamW',\n",
    "    'train_batch_size': 4,\n",
    "    'gradient_accumulation_steps': 8,\n",
    "    'overwrite_output_dir': True,\n",
    "}\n",
    "\n",
    "# Prepare cross validation\n",
    "skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "results_acc = []\n",
    "results_mcc = []\n",
    "results_f1_weighted = []\n",
    "results_f1_micro = []\n",
    "results_f1_macro = []\n",
    "results_eval_loss = []\n",
    "\n",
    "for train_index, val_index in skf.split(X=df['question_pt'], y=df['type']):\n",
    "    # Splitting Dataframe (dataset not included)\n",
    "    train_df = df.iloc[train_index]\n",
    "    val_df = df.iloc[val_index]\n",
    "    \n",
    "    # Defining and training the model\n",
    "    model = ClassificationModel('bert', 'neuralmind/bert-base-portuguese-cased', num_labels=2, args=model_args)\n",
    "    model.train_model(train_df)\n",
    "    \n",
    "    # Validate the model\n",
    "    result, model_outputs, wrong_predictions = model.eval_model(val_df)\n",
    "    preds, _ = model.predict(list(val_df['question_pt']))\n",
    "    \n",
    "    acc = accuracy_score(val_df['type'].values, preds)\n",
    "    mcc = matthews_corrcoef(val_df['type'].values, preds)\n",
    "    f1_weighted = f1_score(val_df['type'].values, preds, average='weighted')\n",
    "    f1_micro = f1_score(val_df['type'].values, preds, average='micro')\n",
    "    f1_macro = f1_score(val_df['type'].values, preds, average='macro')\n",
    "    \n",
    "    # Append model scores\n",
    "    results_acc.append(acc)\n",
    "    results_mcc.append(mcc)\n",
    "    results_f1_weighted.append(f1_weighted)\n",
    "    results_f1_micro.append(f1_micro)\n",
    "    results_f1_macro.append(f1_macro)\n",
    "    results_eval_loss.append(result['eval_loss'])\n",
    "    \n",
    "    print('\\n################# RESULTS #################')\n",
    "    print('\\nAccumulated data:')\n",
    "    print('>> results_acc', results_acc)    \n",
    "    print('>> results_mcc', results_mcc)\n",
    "    print('>> results_f1_weighted', results_f1_weighted)\n",
    "    print('>> results_f1_micro', results_f1_micro)\n",
    "    print('>> results_f1_macro', results_f1_macro)\n",
    "    print('>> results_eval_loss', results_eval_loss)\n",
    "    \n",
    "    print('\\nAVGs:')\n",
    "    print('>> avg_acc:', round(sum(results_acc) / len(results_acc), 3))\n",
    "    print('>> avg_mcc:', round(sum(results_mcc) / len(results_mcc), 3))\n",
    "    print('>> avg_f1_weighted:', round(sum(results_f1_weighted) / len(results_f1_weighted), 3))\n",
    "    print('>> avg_f1_micro:', round(sum(results_f1_micro) / len(results_f1_micro), 3))\n",
    "    print('>> avg_f1_macro:', round(sum(results_f1_macro) / len(results_f1_macro), 3))\n",
    "    print('>> avg_results_eval_loss:', round(sum(results_eval_loss) / len(results_eval_loss), 3))\n",
    "\n",
    "    \n",
    "tac = t.time()\n",
    "duration = round((tac - tic)/60, 2)\n",
    "print('\\n>> Elapsed time: {}min\\n'.format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17425d85",
   "metadata": {},
   "source": [
    "## Check final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c677853f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results with std\n",
      ">> acc: 0.999 +/- 0.001\n",
      ">> mcc: 0.999 +/- 0.001\n",
      ">> f1_weighted: 0.999 +/- 0.001\n",
      ">> f1_micro: 0.999 +/- 0.001\n",
      ">> f1_macro: 0.999 +/- 0.001\n",
      ">> eval_loss: 0.005 +/- 0.004\n"
     ]
    }
   ],
   "source": [
    "print('Final results with std')\n",
    "metrics = ['acc', 'mcc', 'f1_weighted', 'f1_micro', 'f1_macro', 'eval_loss']\n",
    "results = [results_acc, results_mcc, results_f1_weighted, results_f1_micro, results_f1_macro, results_eval_loss]\n",
    "\n",
    "for m, r in zip(metrics, results):\n",
    "    avg = round(statistics.mean(r), 3)\n",
    "    std = round(statistics.stdev(r), 3)\n",
    "    print('>> {}: {} +/- {}'.format(m, avg, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55785281",
   "metadata": {},
   "source": [
    "## Training with the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d66bf1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:615: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c9a7754e5847a78fc600f6ca95990c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9df5764da44eefaff9bda1f07e8757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9640acc17142639669b8d431bc2ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/4556 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blab-answerer/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750b95fe6aa6495fa59eea199e8a4a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/4556 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f740ec8ebcd41d5af2811cf4332a9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/4556 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c70e83b57734eae90d2bdf3526178c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/4556 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f01217c798940d9b3a92f1f6c22f1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/4556 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2845, 0.01409631805715618)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args = {\n",
    "    'num_train_epochs': 5,\n",
    "    'learning_rate': 5e-5,\n",
    "    'max_seq_length': 512,\n",
    "    'n_gpu': 2,\n",
    "    'optimizer': 'AdamW',\n",
    "    'train_batch_size': 4,\n",
    "    'gradient_accumulation_steps': 8,\n",
    "    'overwrite_output_dir': True,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Defining and training the model\n",
    "model = ClassificationModel('bert', 'neuralmind/bert-base-portuguese-cased', num_labels=2, args=model_args)\n",
    "model.train_model(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
